{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nikolas/Downloads/CS-673 (23-24)/Project/msft_causica\n",
      "/home/nikolas/Downloads/CS-673 (23-24)/Project/msft_causica\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "%cd ..\n",
    "# add the src directory for the code\n",
    "sys.path.append('src')\n",
    "\n",
    "%cd .\n",
    "sys.path.append('cdml-neurips2020/datasets/complexity_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # pip uninstall torch torchvision torchaudio\n",
    "# # # pip install torch==1.13.0+cu117 torchvision==0.14.0+cu117 torchaudio==0.13.0+cu117 --extra-index-url https://download.pytorch.org/whl/cu117+\n",
    "# #  NVIDIA-SMI 536.23                 Driver Version: 536.23       CUDA Version: 12.2\n",
    "# import torch\n",
    "# print(\"CUDA Available: \", torch.cuda.is_available())\n",
    "# print(\"CUDA Device Count: \", torch.cuda.device_count())\n",
    "# if torch.cuda.is_available():\n",
    "#     print(\"CUDA Device Name: \", torch.cuda.get_device_name(0))\n",
    "#     print(\"CUDA Device Capability: \", torch.cuda.get_device_capability(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from operator import itemgetter\n",
    "import warnings\n",
    "\n",
    "import fsspec\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from tensordict import TensorDict\n",
    "\n",
    "import pickle \n",
    "\n",
    "from causica.datasets.causica_dataset_format import CAUSICA_DATASETS_PATH, Variable\n",
    "from causica.distributions import ContinuousNoiseDist\n",
    "from causica.lightning.data_modules.basic_data_module import BasicDECIDataModule\n",
    "from causica.lightning.modules.deci_module import DECIModule\n",
    "from causica.sem.sem_distribution import SEMDistributionModule\n",
    "from causica.sem.structural_equation_model import ite\n",
    "from causica.training.auglag import AugLagLRConfig\n",
    "\n",
    "from tigramite.data_processing import DataFrame\n",
    "from tigramite.pcmci import PCMCI\n",
    "from tigramite.independence_tests.parcorr import ParCorr\n",
    "from tigramite import plotting as tp\n",
    "import cdt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "test_run = bool(os.environ.get(\"TEST_RUN\", False))  # used by testing to run the notebook as a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type                  | Params\n",
      "------------------------------------------------------\n",
      "0 | auglag_loss | AugLagLossCalculator  | 0     \n",
      "1 | sem_module  | SEMDistributionModule | 28.1 K\n",
      "------------------------------------------------------\n",
      "28.0 K    Trainable params\n",
      "64        Non-trainable params\n",
      "28.1 K    Total params\n",
      "0.112     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279996a21bbf45579d3038abf6d0dd48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating alpha to: 0.09999999403953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating alpha to: 0.4999999701976776\n",
      "\n",
      "##\n",
      "## Step 1: PC1 algorithm for selecting lagged conditions\n",
      "##\n",
      "\n",
      "Parameters:\n",
      "independence test = par_corr\n",
      "tau_min = 1\n",
      "tau_max = 1\n",
      "pc_alpha = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "max_conds_dim = None\n",
      "max_combinations = 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Resulting lagged parent (super)sets:\n",
      "\n",
      "    Variable X1 has 2 link(s):\n",
      "    [pc_alpha = 0.2]\n",
      "        (X2 -1): max_pval = 0.00003, |min_val| =  0.413\n",
      "        (X3:1 -1): max_pval = 0.14977, |min_val| =  0.148\n",
      "\n",
      "    Variable X2 has 4 link(s):\n",
      "    [pc_alpha = 0.2]\n",
      "        (X1 -1): max_pval = 0.00882, |min_val| =  0.267\n",
      "        (X3 -1): max_pval = 0.01637, |min_val| =  0.246\n",
      "        (X1:1 -1): max_pval = 0.02397, |min_val| =  0.233\n",
      "        (X2 -1): max_pval = 0.12739, |min_val| =  0.157\n",
      "\n",
      "    Variable X3 has 1 link(s):\n",
      "    [pc_alpha = 0.05]\n",
      "        (X2 -1): max_pval = 0.00000, |min_val| =  0.454\n",
      "\n",
      "    Variable Y1 has 4 link(s):\n",
      "    [pc_alpha = 0.2]\n",
      "        (X1 -1): max_pval = 0.06930, |min_val| =  0.186\n",
      "        (X3 -1): max_pval = 0.10956, |min_val| =  0.164\n",
      "        (X2 -1): max_pval = 0.12414, |min_val| =  0.160\n",
      "        (X1:1 -1): max_pval = 0.14279, |min_val| =  0.151\n",
      "\n",
      "    Variable X1:1 has 1 link(s):\n",
      "    [pc_alpha = 0.05]\n",
      "        (X1 -1): max_pval = 0.00000, |min_val| =  1.000\n",
      "\n",
      "    Variable X2:1 has 1 link(s):\n",
      "    [pc_alpha = 0.05]\n",
      "        (X2 -1): max_pval = 0.00000, |min_val| =  1.000\n",
      "\n",
      "    Variable X3:1 has 1 link(s):\n",
      "    [pc_alpha = 0.05]\n",
      "        (X3 -1): max_pval = 0.00000, |min_val| =  1.000\n",
      "\n",
      "    Variable Y1:1 has 1 link(s):\n",
      "    [pc_alpha = 0.05]\n",
      "        (Y1 -1): max_pval = 0.00000, |min_val| =  1.000\n",
      "\n",
      "##\n",
      "## Step 2: MCI algorithm\n",
      "##\n",
      "\n",
      "Parameters:\n",
      "\n",
      "independence test = par_corr\n",
      "tau_min = 0\n",
      "tau_max = 1\n",
      "max_conds_py = None\n",
      "max_conds_px = None\n",
      "\n",
      "## Significant links at alpha = 0.05:\n",
      "\n",
      "    Variable X1 has 1 link(s):\n",
      "        (X2 -1): pval = 0.00006 | val =  0.405\n",
      "\n",
      "    Variable X2 has 1 link(s):\n",
      "        (X1 -1): pval = 0.01852 | val = -0.245\n",
      "\n",
      "    Variable X3 has 1 link(s):\n",
      "        (X2 -1): pval = 0.00007 | val =  0.399\n",
      "\n",
      "    Variable Y1 has 1 link(s):\n",
      "        (X3 -1): pval = 0.00958 | val =  0.267\n",
      "\n",
      "    Variable X1:1 has 7 link(s):\n",
      "        (X1 -1): pval = 0.00000 | val =  1.000\n",
      "        (Y1:1  0): pval = 0.00000 | val =  0.883 | unoriented link\n",
      "        (X1:1 -1): pval = 0.00000 | val =  0.878\n",
      "        (Y1:1 -1): pval = 0.00000 | val =  0.785\n",
      "        (X2:1  0): pval = 0.00000 | val =  0.557 | unoriented link\n",
      "        (X3:1 -1): pval = 0.00001 | val = -0.441\n",
      "        (X2:1 -1): pval = 0.00049 | val =  0.351\n",
      "\n",
      "    Variable X2:1 has 8 link(s):\n",
      "        (X2 -1): pval = 0.00000 | val =  1.000\n",
      "        (X3:1  0): pval = 0.00000 | val = -0.767 | unoriented link\n",
      "        (X3:1 -1): pval = 0.00000 | val = -0.763\n",
      "        (Y1:1 -1): pval = 0.00000 | val =  0.736\n",
      "        (X1:1  0): pval = 0.00000 | val =  0.557 | unoriented link\n",
      "        (X2:1 -1): pval = 0.00000 | val =  0.486\n",
      "        (Y1:1  0): pval = 0.00011 | val = -0.386 | unoriented link\n",
      "        (X1:1 -1): pval = 0.00084 | val =  0.337\n",
      "\n",
      "    Variable X3:1 has 4 link(s):\n",
      "        (X3 -1): pval = 0.00000 | val =  1.000\n",
      "        (Y1:1 -1): pval = 0.00000 | val =  0.805\n",
      "        (X2:1  0): pval = 0.00000 | val = -0.767 | unoriented link\n",
      "        (X3:1 -1): pval = 0.00000 | val = -0.761\n",
      "\n",
      "    Variable Y1:1 has 6 link(s):\n",
      "        (Y1 -1): pval = 0.00000 | val =  1.000\n",
      "        (X1:1  0): pval = 0.00000 | val =  0.883 | unoriented link\n",
      "        (X2:1 -1): pval = 0.00000 | val = -0.852\n",
      "        (X1:1 -1): pval = 0.00000 | val = -0.541\n",
      "        (X2:1  0): pval = 0.00011 | val = -0.386 | unoriented link\n",
      "        (Y1:1 -1): pval = 0.01112 | val =  0.259\n",
      "DECI - Dataset: Complexity 0 Num Features 3 Num Latent 0 Max Lag 1 Min Lag 1 Target Max Parents 3 Max Children 0 Samples 100 Noise 0.01 0.1, SHD: 16, AUPR: 0.2693452380952381, SID: 8, Precision: 0.42857142857142855, Recall: 1.0, F1-Score: 0.6\n",
      "PCMCI - Dataset: Complexity 0 Num Features 3 Num Latent 0 Max Lag 1 Min Lag 1 Target Max Parents 3 Max Children 0 Samples 100 Noise 0.01 0.1, SHD: 58, AUPR: 0.546875, SID: 50, Precision: 0.09375, Recall: 1.0, F1-Score: 0.17142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type                  | Params\n",
      "------------------------------------------------------\n",
      "0 | auglag_loss | AugLagLossCalculator  | 0     \n",
      "1 | sem_module  | SEMDistributionModule | 60.3 K\n",
      "------------------------------------------------------\n",
      "59.7 K    Trainable params\n",
      "576       Non-trainable params\n",
      "60.3 K    Total params\n",
      "0.241     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef72131bff48458c814496f820a5336b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating alpha to: 0.09999999403953552\n",
      "Updating alpha to: 0.4999999701976776\n",
      "Updating alpha to: 2.499999761581421\n",
      "Updating alpha to: 12.499999046325684\n",
      "Updating alpha to: 62.499996185302734\n",
      "\n",
      "##\n",
      "## Step 1: PC1 algorithm for selecting lagged conditions\n",
      "##\n",
      "\n",
      "Parameters:\n",
      "independence test = par_corr\n",
      "tau_min = 1\n",
      "tau_max = 3\n",
      "pc_alpha = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "max_conds_dim = None\n",
      "max_combinations = 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Custom Structural Intervention Distance (SID) metric\n",
    "def compute_sid(predicted_graph, true_graph):\n",
    "    def get_ancestors(graph):\n",
    "        ancestors = {}\n",
    "        for node in graph.nodes():\n",
    "            ancestors[node] = set(nx.ancestors(graph, node))\n",
    "        return ancestors\n",
    "\n",
    "    pred_ancestors = get_ancestors(predicted_graph)\n",
    "    true_ancestors = get_ancestors(true_graph)\n",
    "\n",
    "    sid = 0\n",
    "    for node in true_graph.nodes():\n",
    "        pred_anc = pred_ancestors.get(node, set())\n",
    "        true_anc = true_ancestors.get(node, set())\n",
    "        sid += len(pred_anc.symmetric_difference(true_anc))\n",
    "    \n",
    "    return sid\n",
    "\n",
    "# Function to compute precision, recall, and F1-score for edges\n",
    "def edge_metrics(true_graph, predicted_graph):\n",
    "    true_edges = set(true_graph.edges())\n",
    "    predicted_edges = set(predicted_graph.edges())\n",
    "\n",
    "    true_positives = len(true_edges & predicted_edges)\n",
    "    false_positives = len(predicted_edges - true_edges)\n",
    "    false_negatives = len(true_edges - predicted_edges)\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def train_deci(df, variables_spec, constraint_matrix, root_path, name):\n",
    "    data_module = BasicDECIDataModule(\n",
    "        dataframe=df,\n",
    "        variables=[Variable.from_dict(v) for v in variables_spec],\n",
    "        batch_size=64,\n",
    "        normalize=True \n",
    "    )\n",
    "    num_nodes = len(data_module.dataset_train.keys())\n",
    "    outcome = \"Y1\"\n",
    "    pl.seed_everything(seed=42)\n",
    "\n",
    "    lightning_module = DECIModule(\n",
    "        noise_dist=ContinuousNoiseDist.SPLINE,\n",
    "        embedding_size=64,\n",
    "        out_dim_g=3,\n",
    "        num_layers_g=3,\n",
    "        num_layers_zeta=3,\n",
    "        gumbel_temp=10,\n",
    "        prior_sparsity_lambda=1.0,\n",
    "        init_rho=1.0,\n",
    "        init_alpha=0.020,\n",
    "        auglag_config=AugLagLRConfig(\n",
    "            max_inner_steps=1500,\n",
    "            max_outer_steps=8,\n",
    "            lr_init_dict={\n",
    "                \"icgnn\": 0.00076,\n",
    "                \"vardist\": 0.0098,\n",
    "                \"functional_relationships\": 3e-3,\n",
    "                \"noise_dist\": 0.0070,\n",
    "            },\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    lightning_module.constraint_matrix = torch.tensor(constraint_matrix)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        max_epochs=3000,\n",
    "        fast_dev_run=False,\n",
    "        callbacks=[TQDMProgressBar(refresh_rate=19)],\n",
    "        enable_checkpointing=False\n",
    "    )\n",
    "\n",
    "    trainer.fit(lightning_module, data_module)\n",
    "    \n",
    "    trained_name = name + 'deci_learned_SEM.pt'\n",
    "    save_model_path = os.path.join(root_path, trained_name)\n",
    "    torch.save(lightning_module.sem_module, save_model_path)\n",
    "    return lightning_module\n",
    "\n",
    "def run_pcmci(df):\n",
    "    data_array = df.values\n",
    "    tigramite_df = DataFrame(data_array, var_names=df.columns)\n",
    "    parcorr = ParCorr()\n",
    "    pcmci = PCMCI(dataframe=tigramite_df, cond_ind_test=parcorr, verbosity=1)\n",
    "    max_lag = max([int(node.split(\":\")[1]) for node in df.columns if \":\" in node])\n",
    "    results = pcmci.run_pcmci(tau_max=max_lag, pc_alpha=None)\n",
    "    link_matrix = results['graph']\n",
    "\n",
    "    pcmci_graph = nx.DiGraph()\n",
    "    for i in range(link_matrix.shape[0]):\n",
    "        for j in range(link_matrix.shape[1]):\n",
    "            if link_matrix[i, j] != 0:\n",
    "                pcmci_graph.add_edge(df.columns[i], df.columns[j])\n",
    "    return pcmci_graph\n",
    "\n",
    "def evaluate_model(graph, gt_graph):\n",
    "    pcmci_adj_matrix = nx.to_numpy_array(graph, weight=None).astype(np.float64)\n",
    "    gt_adj_matrix = nx.to_numpy_array(gt_graph, weight=None).astype(np.float64)\n",
    "    pcmci_graph_float = nx.from_numpy_array(pcmci_adj_matrix, create_using=nx.DiGraph)\n",
    "    gt_graph_float = nx.from_numpy_array(gt_adj_matrix, create_using=nx.DiGraph)\n",
    "    shd = cdt.metrics.SHD(gt_graph_float, pcmci_graph_float, double_for_anticausal=True)\n",
    "    aupr, curve = cdt.metrics.precision_recall(gt_graph_float, pcmci_graph_float, low_confidence_undirected=True)\n",
    "    sid = compute_sid(graph, gt_graph)\n",
    "    precision, recall, f1_score = edge_metrics(gt_graph, graph)\n",
    "    return shd, aupr, sid, precision, recall, f1_score\n",
    "\n",
    "root_path = '../cdml-neurips2020/datasets/'\n",
    "complexities = ['complexity_0']\n",
    "# complexities = ['complexity_0', 'complexity_10', 'complexity_30']\n",
    "\n",
    "# File paths for DECI and PCMCI evaluation metrics\n",
    "deci_metrics_file = os.path.join(root_path, 'deci_evaluation_metrics.csv')\n",
    "pcmci_metrics_file = os.path.join(root_path, 'pcmci_evaluation_metrics.csv')\n",
    "\n",
    "# Initialize metrics files\n",
    "with open(deci_metrics_file, 'w') as f:\n",
    "    f.write('Dataset,SHD,AUPR,SID,Precision,Recall,F1-Score\\n')\n",
    "with open(pcmci_metrics_file, 'w') as f:\n",
    "    f.write('Dataset,SHD,AUPR,SID,Precision,Recall,F1-Score\\n')\n",
    "\n",
    "for complexity in complexities:\n",
    "    dataset_path = os.path.join(root_path, complexity)\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        if filename.endswith('-lagged.csv'):\n",
    "            df = pd.read_csv(os.path.join(dataset_path, filename))\n",
    "            name = filename.replace('-lagged.csv', '')\n",
    "            variables_spec = []\n",
    "            for col in df.columns:\n",
    "                variables_spec.append({\"name\": col, \"type\": \"continuous\", \"group_name\": col})\n",
    "            \n",
    "            variables_path = os.path.join(dataset_path, filename.replace('.csv', '.json'))\n",
    "            with fsspec.open(variables_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump({\"variables\": variables_spec}, f, indent=2)\n",
    "\n",
    "            with fsspec.open(variables_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "                variables_spec = json.load(f)[\"variables\"]\n",
    "            \n",
    "            # Generate constraint matrix\n",
    "            node_names = df.columns.tolist()\n",
    "            num_nodes = len(node_names)\n",
    "            max_lag = max([int(node.split(\":\")[1]) for node in node_names if \":\" in node])\n",
    "            constraint_matrix = np.full((num_nodes, num_nodes), np.nan, dtype=np.float32)\n",
    "            node_name_to_idx = {key: i for i, key in enumerate(node_names)}\n",
    "            \n",
    "            for node in node_names:\n",
    "                for node_2 in node_names:\n",
    "                    suffix = node.split(\":\")[1] if \":\" in node else None\n",
    "                    suffix_2 = node_2.split(\":\")[1] if \":\" in node_2 else None\n",
    "                    if suffix is not None and suffix_2 is not None and suffix == suffix_2:\n",
    "                        constraint_matrix[node_name_to_idx[node], node_name_to_idx[node_2]] = 0\n",
    "                        constraint_matrix[node_name_to_idx[node_2], node_name_to_idx[node]] = 0\n",
    "                    if \":\" not in node:\n",
    "                        constraint_matrix[node_name_to_idx[node], :] = 0\n",
    "                    prefix_2 = node_2.split(\":\")[0]\n",
    "                    if node == node_2:\n",
    "                        constraint_matrix[node_name_to_idx[node], node_name_to_idx[node_2]] = 0\n",
    "                    if prefix_2 == node:\n",
    "                        constraint_matrix[node_name_to_idx[node], node_name_to_idx[node_2]] = 0\n",
    "                    if \":\" in node_2 and node == node_2.split(\":\")[1]:\n",
    "                        constraint_matrix[node_name_to_idx[node], node_name_to_idx[node_2]] = 0\n",
    "                        constraint_matrix[node_name_to_idx[node_2], node_name_to_idx[node]] = 0\n",
    "                    if \":\" in node and \":\" in node_2 and int(node.split(\":\")[1]) < int(node_2.split(\":\")[1]):\n",
    "                        constraint_matrix[node_name_to_idx[node], node_name_to_idx[node_2]] = 0\n",
    "                    if \":\" not in node and \":\" in node_2:\n",
    "                        constraint_matrix[node_name_to_idx[node], node_name_to_idx[node_2]] = 0            \n",
    "\n",
    "            # Train DECI\n",
    "            lightning_module = train_deci(df, variables_spec, constraint_matrix, dataset_path, name)\n",
    "\n",
    "            # Run PCMCI\n",
    "            pcmci_graph = run_pcmci(df)\n",
    "\n",
    "            # Load and clean ground truth graph\n",
    "            graph_filename = os.path.join(dataset_path, filename.split('-')[0] + '-causal_graph.pkl')\n",
    "            with open(graph_filename, 'rb') as f:\n",
    "                gt_graph = pickle.load(f)\n",
    "\n",
    "            for node in list(gt_graph.nodes):\n",
    "                if node.startswith('S'):\n",
    "                    gt_graph.remove_node(node)\n",
    "            for edge in list(gt_graph.edges):\n",
    "                if edge[0].startswith('S') or edge[1].startswith('S'):\n",
    "                    gt_graph.remove_edge(edge[0], edge[1])\n",
    "            for node in list(gt_graph.nodes):\n",
    "                new_name = node.replace('_t', '').replace('_', '_').replace(':1', ':1').replace('-', ':')\n",
    "                nx.relabel_nodes(gt_graph, {node: new_name}, copy=False)\n",
    "\n",
    "            # Evaluate DECI model\n",
    "            deci_graph = nx.from_numpy_array(lightning_module.sem_module().mode.graph.cpu().numpy(), create_using=nx.DiGraph)\n",
    "            deci_graph = nx.relabel_nodes(deci_graph, {i: key for i, key in enumerate(df.columns)})\n",
    "            deci_shd, deci_aupr, deci_sid, deci_precision, deci_recall, deci_f1_score = evaluate_model(deci_graph, gt_graph)\n",
    "            print(f'DECI - Dataset: {name}, SHD: {deci_shd}, AUPR: {deci_aupr}, SID: {deci_sid}, Precision: {deci_precision}, Recall: {deci_recall}, F1-Score: {deci_f1_score}')\n",
    "            with open(deci_metrics_file, 'a') as f:\n",
    "                f.write(f'{name},{deci_shd},{deci_aupr},{deci_sid},{deci_precision},{deci_recall},{deci_f1_score}\\n')\n",
    "\n",
    "            # Evaluate PCMCI model\n",
    "            pcmci_shd, pcmci_aupr, pcmci_sid, pcmci_precision, pcmci_recall, pcmci_f1_score = evaluate_model(pcmci_graph, gt_graph)\n",
    "            print(f'PCMCI - Dataset: {name}, SHD: {pcmci_shd}, AUPR: {pcmci_aupr}, SID: {pcmci_sid}, Precision: {pcmci_precision}, Recall: {pcmci_recall}, F1-Score: {pcmci_f1_score}')\n",
    "            with open(pcmci_metrics_file, 'a') as f:\n",
    "                f.write(f'{name},{pcmci_shd},{pcmci_aupr},{pcmci_sid},{pcmci_precision},{pcmci_recall},{pcmci_f1_score}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
